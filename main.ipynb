{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import (\n",
    "    median_absolute_error,\n",
    "    max_error,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Utils import Utils\n",
    "from DecisionTreeRegressor import DecisionTreeRegressor\n",
    "from RandomForestRegressor import RandomForestRegressor\n",
    "from LinearRegression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('./NSO_Population_Sex_dataset/NSO_POPULATION_DATA_CLEANED.csv')\n",
    "\n",
    "# Define feature columns and target variable\n",
    "feature_cols = ['District', 'Sex', 'Year', 'Population_Growth_Rate', 'Average_Population']\n",
    "X = pd.get_dummies(df[feature_cols], columns=['District', 'Sex'])\n",
    "y = df[\"Population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Implementations - Decision Tree, Random Forest, Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_RUNS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Decision Tree, Random Forest, and Linear Regression\n",
    "DT_Parameters = {\n",
    "    'min_samples_split': [2, 3, 4, 5, 10, 15, 20],\n",
    "    'max_depth': [10, 25, 50, 75, 100, 125, 150, 175, 200]\n",
    "}\n",
    "\n",
    "RF_Parameters = {\n",
    "    'n_estimators': [75, 100, 125],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_depth': [25, 50, 75, 100]\n",
    "}\n",
    "\n",
    "LR_Parameters = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'num_iterations': [50, 100, 250, 500, 750, 1000, 1250, 1500]\n",
    "}\n",
    "\n",
    "# Lists to store results for each algorithm\n",
    "DT_All_Best_Predictions, RF_All_Best_Predictions, LR_All_Best_Predictions = [], [], []\n",
    "DT_Total_Time, DT_Total_MSE, DT_Total_MAE, DT_Total_RMSE, DT_Total_R2, DT_Total_Explained_Variance, DT_Total_MedianAE, DT_Total_MaxError = [0.0] * 8\n",
    "RF_Total_Time, RF_Total_MSE, RF_Total_MAE, RF_Total_RMSE, RF_Total_R2, RF_Total_Explained_Variance, RF_Total_MedianAE, RF_Total_MaxError = [0.0] * 8\n",
    "LR_Total_Time, LR_Total_MSE, LR_Total_MAE, LR_Total_RMSE, LR_Total_R2, LR_Total_Explained_Variance, LR_Total_MedianAE, LR_Total_MaxError = [0.0] * 8\n",
    "\n",
    "# Lists to store actual values for each algorithm\n",
    "All_Actual_Values = []\n",
    "\n",
    "for run in range(NUMBER_OF_RUNS):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=run)\n",
    "\n",
    "    All_Actual_Values.append(y_test.values)\n",
    "\n",
    "    DT_Best_Model, DT_Best_Prediction, DT_Best_Parameters, DT_Best_Time, DT_Best_MSE = None, None, None, None, float('inf')\n",
    "    RF_Best_Model, RF_Best_Prediction, RF_Best_Parameters, RF_Best_Time, RF_Best_MSE = None, None, None, None, float('inf')\n",
    "    LR_Best_Model, LR_Best_Prediction, LR_Best_Parameters, LR_Best_Time, LR_Best_MSE = None, None, None, None, float('inf')\n",
    "\n",
    "    # Decision Tree\n",
    "    for min_samples_split in DT_Parameters['min_samples_split']:\n",
    "        for max_depth in DT_Parameters['max_depth']:\n",
    "            DT_Start_Time = time.time()\n",
    "            DT_Temp_Model = DecisionTreeRegressor(min_samples_split=min_samples_split, max_depth=max_depth)\n",
    "            DT_Temp_Model.fit(X_train.values, y_train.values)\n",
    "            DT_Temp_Prediction = DT_Temp_Model.predict(X_test.values)\n",
    "            DT_End_Time = time.time()\n",
    "            DT_Temp_Time = DT_End_Time - DT_Start_Time\n",
    "            DT_Temp_MSE = mean_squared_error(y_test, DT_Temp_Prediction)\n",
    "\n",
    "            # Determining best hyperparameters based on MSE\n",
    "            if DT_Temp_MSE < DT_Best_MSE:\n",
    "                DT_Best_Model, DT_Best_Parameters, DT_Best_Prediction, DT_Best_Time, DT_Best_MSE = DT_Temp_Model, {'min_samples_split': min_samples_split, 'max_depth': max_depth}, DT_Temp_Prediction, DT_Temp_Time, DT_Temp_MSE\n",
    "\n",
    "    # Random Forest\n",
    "    for n_estimators in RF_Parameters['n_estimators']:\n",
    "        for min_sample_split in RF_Parameters['min_samples_split']:\n",
    "            for max_depth in RF_Parameters['max_depth']:\n",
    "                RF_Start_Time = time.time()\n",
    "                RF_Temp_Model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_sample_split)\n",
    "                RF_Temp_Model.fit(X_train, y_train)\n",
    "                RF_Temp_Prediction = RF_Temp_Model.predict(X_test)\n",
    "                RF_End_Time = time.time()\n",
    "                RF_Temp_Time = RF_End_Time - RF_Start_Time\n",
    "                RF_Temp_MSE = mean_squared_error(y_test, RF_Temp_Prediction)\n",
    "\n",
    "                # Determining best hyperparameters based on MSE\n",
    "                if RF_Temp_MSE < RF_Best_MSE:\n",
    "                    RF_Best_Model, RF_Best_Parameters, RF_Best_Prediction, RF_Best_Time, RF_Best_MSE = RF_Temp_Model, {'n_estimators': n_estimators, 'min_samples_split': min_sample_split, 'max_depth': max_depth}, RF_Temp_Prediction, RF_Temp_Time, RF_Temp_MSE\n",
    "\n",
    "    # Linear Regression\n",
    "    for learning_rate in LR_Parameters['learning_rate']:\n",
    "        for num_iterations in LR_Parameters['num_iterations']:\n",
    "            LR_Start_Time = time.time()\n",
    "            LR_Temp_Model = LinearRegression(learning_rate=learning_rate, num_iterations=num_iterations)\n",
    "            LR_Temp_Model.fit(X_train.values, y_train.values)\n",
    "            LR_Temp_Prediction = LR_Temp_Model.predict(X_test.values)\n",
    "            LR_End_Time = time.time()\n",
    "            LR_Temp_Time = LR_End_Time - LR_Start_Time\n",
    "            LR_Temp_MSE = mean_squared_error(y_test, LR_Temp_Prediction)\n",
    "\n",
    "            # Determining best hyperparameters based on MSE\n",
    "            if LR_Temp_MSE < LR_Best_MSE:\n",
    "                LR_Best_Model, LR_Best_Parameters, LR_Best_Prediction, LR_Best_Time, LR_Best_MSE = LR_Temp_Model, {'learning_rate': learning_rate, 'num_iterations': num_iterations}, LR_Temp_Prediction, LR_Temp_Time, LR_Temp_MSE\n",
    "\n",
    "    # Store values to find averages after all runs are finished\n",
    "    DT_All_Best_Predictions.append(DT_Best_Prediction)\n",
    "    DT_Total_Time += DT_Best_Time\n",
    "    DT_Total_MSE += DT_Best_MSE\n",
    "    DT_Total_MAE += mean_absolute_error(y_test, DT_Best_Prediction)\n",
    "    DT_Total_RMSE += Utils.root_mean_squared_error(y_test, DT_Best_Prediction)\n",
    "    DT_Total_R2 += r2_score(y_test, DT_Best_Prediction)\n",
    "    DT_Total_Explained_Variance += explained_variance_score(y_test, DT_Best_Prediction)\n",
    "    DT_Total_MedianAE += median_absolute_error(y_test, DT_Best_Prediction)\n",
    "    DT_Total_MaxError += max_error(y_test, DT_Best_Prediction)\n",
    "\n",
    "    RF_All_Best_Predictions.append(RF_Best_Prediction)\n",
    "    RF_Total_Time += RF_Best_Time\n",
    "    RF_Total_MSE += RF_Best_MSE\n",
    "    RF_Total_MAE += mean_absolute_error(y_test, RF_Best_Prediction)\n",
    "    RF_Total_RMSE += Utils.root_mean_squared_error(y_test, RF_Best_Prediction)\n",
    "    RF_Total_R2 += r2_score(y_test, RF_Best_Prediction)\n",
    "    RF_Total_Explained_Variance += explained_variance_score(y_test, RF_Best_Prediction)\n",
    "    RF_Total_MedianAE += median_absolute_error(y_test, RF_Best_Prediction)\n",
    "    RF_Total_MaxError += max_error(y_test, RF_Best_Prediction)\n",
    "\n",
    "    LR_All_Best_Predictions.append(LR_Best_Prediction)\n",
    "    LR_Total_Time += LR_Best_Time\n",
    "    LR_Total_MSE += LR_Best_MSE\n",
    "    LR_Total_MAE += mean_absolute_error(y_test, LR_Best_Prediction)\n",
    "    LR_Total_RMSE += Utils.root_mean_squared_error(y_test, LR_Best_Prediction)\n",
    "    LR_Total_R2 += r2_score(y_test, LR_Best_Prediction)\n",
    "    LR_Total_Explained_Variance += explained_variance_score(y_test, LR_Best_Prediction)\n",
    "    LR_Total_MedianAE += median_absolute_error(y_test, LR_Best_Prediction)\n",
    "    LR_Total_MaxError += max_error(y_test, LR_Best_Prediction)\n",
    "\n",
    "    print(f\"Run {run + 1}\")\n",
    "\n",
    "# Finding average values across all runs\n",
    "Average_Actual_Values = np.mean(All_Actual_Values, axis=0)\n",
    "\n",
    "DT_Average_Predictions = np.mean(DT_All_Best_Predictions, axis=0)\n",
    "DT_Average_Time = DT_Total_Time / NUMBER_OF_RUNS\n",
    "DT_Average_MSE = DT_Total_MSE / NUMBER_OF_RUNS\n",
    "DT_Average_MAE = DT_Total_MAE / NUMBER_OF_RUNS\n",
    "DT_Average_RMSE = DT_Total_RMSE / NUMBER_OF_RUNS\n",
    "DT_Average_R2 = DT_Total_R2 / NUMBER_OF_RUNS\n",
    "DT_Average_Explained_Variance = DT_Total_Explained_Variance / NUMBER_OF_RUNS\n",
    "DT_Average_MedianAE = DT_Total_MedianAE / NUMBER_OF_RUNS\n",
    "DT_Average_MaxError = DT_Total_MaxError / NUMBER_OF_RUNS\n",
    "\n",
    "RF_Average_Predictions = np.mean(RF_All_Best_Predictions, axis=0)\n",
    "RF_Average_Time = RF_Total_Time / NUMBER_OF_RUNS\n",
    "RF_Average_MSE = RF_Total_MSE / NUMBER_OF_RUNS\n",
    "RF_Average_MAE = RF_Total_MAE / NUMBER_OF_RUNS\n",
    "RF_Average_RMSE = RF_Total_RMSE / NUMBER_OF_RUNS\n",
    "RF_Average_R2 = RF_Total_R2 / NUMBER_OF_RUNS\n",
    "RF_Average_Explained_Variance = RF_Total_Explained_Variance / NUMBER_OF_RUNS\n",
    "RF_Average_MedianAE = RF_Total_MedianAE / NUMBER_OF_RUNS\n",
    "RF_Average_MaxError = RF_Total_MaxError / NUMBER_OF_RUNS\n",
    "\n",
    "LR_Average_Predictions = np.mean(LR_All_Best_Predictions, axis=0)\n",
    "LR_Average_Time = LR_Total_Time / NUMBER_OF_RUNS\n",
    "LR_Average_MSE = LR_Total_MSE / NUMBER_OF_RUNS\n",
    "LR_Average_MAE = LR_Total_MAE / NUMBER_OF_RUNS\n",
    "LR_Average_RMSE = LR_Total_RMSE / NUMBER_OF_RUNS\n",
    "LR_Average_R2 = LR_Total_R2 / NUMBER_OF_RUNS\n",
    "LR_Average_Explained_Variance = LR_Total_Explained_Variance / NUMBER_OF_RUNS\n",
    "LR_Average_MedianAE = LR_Total_MedianAE / NUMBER_OF_RUNS\n",
    "LR_Average_MaxError = LR_Total_MaxError / NUMBER_OF_RUNS\n",
    "\n",
    "print(f\"\\nDecision Tree Metrics over {NUMBER_OF_RUNS} runs:\")\n",
    "print(f\"Average Execution Time in seconds: {DT_Average_Time:.6f}\")\n",
    "print(f\"Average Mean Squared Error: {DT_Average_MSE:.6f}\")\n",
    "print(f\"Average Root Mean Squared Error: {DT_Average_RMSE:.6f}\")\n",
    "print(f\"Average Mean Absolute Error: {DT_Average_MAE:.6f}\")\n",
    "print(f\"Average R Squared: {DT_Average_R2:.6f}\")\n",
    "print(f\"Average Explained Variance: {DT_Average_Explained_Variance:.6f}\")\n",
    "print(f\"Average Median Absolute Error: {DT_Average_MedianAE:.6f}\")\n",
    "print(f\"Average Max Error: {DT_Average_MaxError:.6f}\")\n",
    "\n",
    "print(f\"\\nRandom Forest Metrics over {NUMBER_OF_RUNS} runs:\")\n",
    "print(f\"Average Execution Time in seconds: {RF_Average_Time:.6f}\")\n",
    "print(f\"Average Mean Squared Error: {RF_Average_MSE:.6f}\")\n",
    "print(f\"Average Root Mean Squared Error: {RF_Average_RMSE:.6f}\")\n",
    "print(f\"Average Mean Absolute Error: {RF_Average_MAE:.6f}\")\n",
    "print(f\"Average R Squared: {RF_Average_R2:.6f}\")\n",
    "print(f\"Average Explained Variance: {RF_Average_Explained_Variance:.6f}\")\n",
    "print(f\"Average Median Absolute Error: {RF_Average_MedianAE:.6f}\")\n",
    "print(f\"Average Max Error: {RF_Average_MaxError:.6f}\")\n",
    "\n",
    "print(f\"\\nLinear Regression Metrics over {NUMBER_OF_RUNS} runs:\")\n",
    "print(f\"Average Execution Time in seconds: {LR_Average_Time:.6f}\")\n",
    "print(f\"Average Mean Squared Error: {LR_Average_MSE:.6f}\")\n",
    "print(f\"Average Root Mean Squared Error: {LR_Average_RMSE:.6f}\")\n",
    "print(f\"Average Mean Absolute Error: {LR_Average_MAE:.6f}\")\n",
    "print(f\"Average R Squared: {LR_Average_R2:.6f}\")\n",
    "print(f\"Average Explained Variance: {LR_Average_Explained_Variance:.6f}\")\n",
    "print(f\"Average Median Absolute Error: {LR_Average_MedianAE:.6f}\")\n",
    "print(f\"Average Max Error: {LR_Average_MaxError:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring actual and predicted value lists are numeric arrays\n",
    "Average_Actual_Values_Numeric = np.asarray(Average_Actual_Values, dtype=np.float64)\n",
    "DT_Average_Prediction_Numeric = np.asarray(DT_Average_Predictions, dtype=np.float64)\n",
    "RF_Average_Prediction_Numeric = np.asarray(RF_Average_Predictions, dtype=np.float64)\n",
    "LR_Average_Prediction_Numeric = np.asarray(LR_Average_Predictions, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot - Actual vs Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Decision Tree vs Custom Random Forest vs Custom Linear Regression\n",
    "plt.scatter(Average_Actual_Values_Numeric, DT_Average_Prediction_Numeric, alpha=0.7, marker='o', label='Custom Decision Tree')\n",
    "plt.scatter(Average_Actual_Values_Numeric, RF_Average_Prediction_Numeric, alpha=0.7, marker='s', label='Custom Random Forest')\n",
    "plt.scatter(Average_Actual_Values_Numeric, LR_Average_Prediction_Numeric, alpha=0.7, marker='^', label='Custom Linear Regression')\n",
    "\n",
    "# Regression lines\n",
    "plt.plot(np.unique(Average_Actual_Values_Numeric), np.poly1d(np.polyfit(Average_Actual_Values_Numeric, DT_Average_Prediction_Numeric, 1))(np.unique(Average_Actual_Values_Numeric)), color='blue', linestyle='--')\n",
    "plt.plot(np.unique(Average_Actual_Values_Numeric), np.poly1d(np.polyfit(Average_Actual_Values_Numeric, RF_Average_Prediction_Numeric, 1))(np.unique(Average_Actual_Values_Numeric)), color='orange', linestyle='--')\n",
    "plt.plot(np.unique(Average_Actual_Values_Numeric), np.poly1d(np.polyfit(Average_Actual_Values_Numeric, LR_Average_Prediction_Numeric, 1))(np.unique(Average_Actual_Values_Numeric)), color='green', linestyle='--')\n",
    "\n",
    "# Reference line\n",
    "plt.plot([min(Average_Actual_Values_Numeric), max(Average_Actual_Values_Numeric)], [min(Average_Actual_Values_Numeric), max(Average_Actual_Values_Numeric)], linestyle='-', color='black')\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Average Predicted Values Scatter Plot - Custom Implementations')\n",
    "\n",
    "plt.legend(['Custom Decision Tree', 'Custom Random Forest', 'Custom Linear Regression'], loc='lower center', bbox_to_anchor=(0.5,-0.5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Plot - Actual vs Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Decision Tree vs Custom Random Forest vs Custom Linear Regression\n",
    "plt.plot(Average_Actual_Values_Numeric, label='Actual', color='black', linestyle='-')\n",
    "plt.plot(DT_Average_Prediction_Numeric, label='Decision Tree', alpha=0.8, linestyle='--')\n",
    "plt.plot(RF_Average_Prediction_Numeric, label='Random Forest', alpha=0.8, linestyle='--')\n",
    "plt.plot(LR_Average_Prediction_Numeric, label='Linear Regression', alpha=0.8, linestyle='--')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Target Variable (Values)')\n",
    "plt.title('Actual vs Average Predicted Line Plot - Custom Implementations')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5,-0.5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Residuals = Average_Actual_Values_Numeric - DT_Average_Prediction_Numeric\n",
    "RF_Residuals = Average_Actual_Values_Numeric - RF_Average_Prediction_Numeric\n",
    "LR_Residuals = Average_Actual_Values_Numeric - LR_Average_Prediction_Numeric\n",
    "\n",
    "# Plot for Custom Decision Tree\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Average_Actual_Values_Numeric, DT_Residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Custom Decision Tree Residuals')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for Custom Random Forest\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Average_Actual_Values_Numeric, RF_Residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Custom Random Forest Residuals')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for Custom Linear Regression\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Average_Actual_Values_Numeric, LR_Residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Custom Linear Regression Residuals')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals vs. Predicted Values for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(DT_Average_Prediction_Numeric, DT_Residuals, label='Decision Tree Residuals')\n",
    "plt.scatter(RF_Average_Prediction_Numeric, RF_Residuals, label='Random Forest Residuals')\n",
    "plt.scatter(LR_Average_Prediction_Numeric, LR_Residuals, label='Linear Regression Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='--', label='Residuals Mean')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Average Predicted Values')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5,-0.25))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average: Execution time in seconds, Mean Absolute Error, Median Absolute Error, Mean Squared Error, Root Mean Squared Error, R Squared, Explained Variance, Maximum Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = {\n",
    "    '': ['Custom Decision Tree Regressor', 'Custom Random Forest Regressor', 'Custom Linear Regression'],\n",
    "    'Average Execution Time in seconds': [DT_Average_Time, RF_Average_Time, LR_Average_Time],\n",
    "    'Average Mean Absolute Error': [DT_Average_MAE, RF_Average_MAE, RF_Average_MAE],\n",
    "    'Average Median Absolute Error': [DT_Average_MedianAE, RF_Average_MedianAE, LR_Average_MedianAE],\n",
    "    'Average Mean Squared Error': [DT_Average_MSE, RF_Average_MSE, LR_Average_MSE],\n",
    "    'Average Root Mean Squared Error': [DT_Average_RMSE, RF_Average_RMSE, LR_Average_RMSE],\n",
    "    'Average R Squared': [DT_Average_R2, RF_Average_R2, LR_Average_R2],\n",
    "    'Average Explained Variance': [DT_Average_Explained_Variance, RF_Average_Explained_Variance, LR_Average_Explained_Variance],\n",
    "    'Average Maximum Absolute Error': [DT_Average_MaxError, RF_Average_MaxError, LR_Average_MaxError]\n",
    "}\n",
    "\n",
    "print(tabulate(table_data, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual vs Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_data = {\n",
    "    'Average Actual Values': Average_Actual_Values_Numeric,\n",
    "    'Average DT Predicted Values': DT_Average_Prediction_Numeric,\n",
    "    'Average RF Predicted Values': RF_Average_Prediction_Numeric,\n",
    "    'Average LR Predicted Values': LR_Average_Prediction_Numeric\n",
    "}\n",
    "\n",
    "print(tabulate(results_table_data, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(Average_Actual_Values_Numeric, label='Actual Values', color='black', linestyle='-')\n",
    "sns.kdeplot(DT_Average_Prediction_Numeric, label='Average Decision Tree Predictions', alpha=0.8, linestyle='--')\n",
    "sns.kdeplot(RF_Average_Prediction_Numeric, label='Average Random Forest Predictions', alpha=0.8, linestyle='--')\n",
    "sns.kdeplot(LR_Average_Prediction_Numeric, label='Average Linear Regression Predictions', alpha=0.8, linestyle='--')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Actual vs Average Predicted Values')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5,-0.4))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
